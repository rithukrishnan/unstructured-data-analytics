{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TAProjectPS5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlmB5Ozc0Yhz",
        "outputId": "4a10e598-c4ab-4f18-d1b6-2fc614da49c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=4a6f5d895b94f84006a936291711e4a2ebebacc89ee0597002b80f7f54b7e71d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-djq_u480/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e79Ovtu0rxc"
      },
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hh7CJbF0scb"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdcYckRFA1GJ",
        "outputId": "d2d048cf-96c5-4d36-8ba0-e0ea4283b8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Read in the scrape results\n",
        "rgames = pd.read_csv('rps5_comments.csv')#,sep = '\\t')\n",
        "rgames[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>created</th>\n",
              "      <th>url_of_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i1rhdh</td>\n",
              "      <td>Semifreak</td>\n",
              "      <td>**Full list of 120fps Xbox Series X games**\\n\\...</td>\n",
              "      <td>1227</td>\n",
              "      <td>1.596288e+09</td>\n",
              "      <td>/r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i1rhdh</td>\n",
              "      <td>Task876</td>\n",
              "      <td>Don't most 4k TVs only run at 60hz when at 4k?</td>\n",
              "      <td>788</td>\n",
              "      <td>1.596288e+09</td>\n",
              "      <td>/r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i1rhdh</td>\n",
              "      <td>Tstinzy</td>\n",
              "      <td>When a developer says the game “supports” 120f...</td>\n",
              "      <td>163</td>\n",
              "      <td>1.596291e+09</td>\n",
              "      <td>/r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i1rhdh</td>\n",
              "      <td>DerpHog</td>\n",
              "      <td>The way tech news keeps hearing \"supports up t...</td>\n",
              "      <td>72</td>\n",
              "      <td>1.596296e+09</td>\n",
              "      <td>/r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i1rhdh</td>\n",
              "      <td>PvtCMiller</td>\n",
              "      <td>This article seems like clickbait just to prom...</td>\n",
              "      <td>56</td>\n",
              "      <td>1.596287e+09</td>\n",
              "      <td>/r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  submission  ...                                        url_of_post\n",
              "0     i1rhdh  ...  /r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...\n",
              "1     i1rhdh  ...  /r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...\n",
              "2     i1rhdh  ...  /r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...\n",
              "3     i1rhdh  ...  /r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...\n",
              "4     i1rhdh  ...  /r/PS5/comments/i1rhdh/all_ps5_and_xbox_series...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMxGCS6DATA"
      },
      "source": [
        "###Attribute frequency to determine top five"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAx5fJy-A7Is",
        "outputId": "a5891f27-e302-45d1-b5e2-af029b062f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "#We need to filter out stopwords\n",
        "from nltk.corpus import stopwords\n",
        "#Use nltk's stopwords list\n",
        "stopwords_list = stopwords.words('english')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8CEJpR_CNZa"
      },
      "source": [
        "#clean_comment accepts a string. It then cleans the comment by removing punctuation and stopwords.\n",
        "#It returns a list of words in that string.\n",
        "def clean_comment(comment):\n",
        "    #For cleaning up the test comment. Remove punctuation and make everything lower case.\n",
        "    comment = re.sub(r'[^\\w\\s]','',comment.lower())\n",
        "    \n",
        "    #Syntax translation:\n",
        "    #word can be anything. I choose word since it's what we're essentially doing\n",
        "    #comment.split() converts the comment into a list. \n",
        "    #Then see if the word in that list is in the drop_stop or not. \n",
        "    #Drops any word that is in the stopwords list.\n",
        "    stopwords_list = stopwords.words('english')\n",
        "    #Store this list and return it.\n",
        "    cleaned = [word for word in comment.split() if word not in stopwords_list]\n",
        "    return cleaned"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ktu50BCOwJ"
      },
      "source": [
        "#Use function to create a new cleaned comment column.\n",
        "rgames['cleaned comment'] = rgames['body'].astype(str).apply(clean_comment)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p2ToBmFBPf0"
      },
      "source": [
        "#Accepts a list of words as a parameter.\n",
        "#Counts word occurrences and stores it as a dictionary which is returned.\n",
        "def create_word_count(word_list):\n",
        "    #Create dictionary that acts as the values for the main frame.\n",
        "    word_frequency={}\n",
        "\n",
        "    for word in word_list: #Take each word in the words list.\n",
        "        if word in word_frequency: #If I have seen this word, update number of times seen by 1\n",
        "            word_frequency[word] +=1\n",
        "        else: #I have not seen this word yet. Put it in as a key value.\n",
        "            word_frequency[word]  = 1\n",
        "    return word_frequency"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvsnX-m2CpHW"
      },
      "source": [
        "#Create a new column that contains the word frequency dictionaries\n",
        "rgames['count dictionary'] = rgames['cleaned comment'].map(create_word_count)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qIww-zLBlqo"
      },
      "source": [
        "#Create a list of attributes that we think belong \n",
        "attribute_list = ['performance','graphics','affordable','favorite','buy','speed',\n",
        "                 'price','security','fps','games','multiplayer','online','subscription',\n",
        "                  'quality']\n",
        "#Feel free to append or add more to the list\n",
        "#attribute_list.append('Phrase here')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyd2pLYLBx5I"
      },
      "source": [
        "attribute_df = pd.DataFrame(index = attribute_list)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-zTOLBRB0LM"
      },
      "source": [
        "attribute_df['frequency'] = 0"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhuopaF3B6uM"
      },
      "source": [
        "#Count the number of times a brand has been mentioned in a message/comment throughout the entire df\n",
        "for dictionary in rgames['count dictionary']: #Take each dictionary\n",
        "    for key,value in dictionary.items(): #For each key (word) and value (frequency)\n",
        "        if key in attribute_list: #The key matches a word in the attribute list.\n",
        "            #Add 1 to the value of the word it matched in the dataframe.\n",
        "            attribute_df.loc[key] += 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja9un_rqCyvV",
        "outputId": "d666181d-cb8c-41a0-89a1-9e1213abb6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "attribute_df.sort_values(by='frequency',ascending=False)[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>buy</th>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>graphics</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quality</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          frequency\n",
              "games           421\n",
              "buy             168\n",
              "price           129\n",
              "graphics         42\n",
              "quality          41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inCJKfCzDGEU"
      },
      "source": [
        "###General Word frequency analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKTv01dpDOcW"
      },
      "source": [
        "#Import everything.\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import manifold\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords # Import the stop word list\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMYEm6biDdv9"
      },
      "source": [
        "#create a new data frame for beers. Clean up the reviews even more for word tokenization.\n",
        "rgames2 = rgames[['author','body']].copy()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87fp0V8pDvKB"
      },
      "source": [
        "#Replace punctuation with blanks. \n",
        "rgames2['new_cleaned_review'] = rgames2['body'].str.replace(r'[^\\w\\s]+', '')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg-xfbMxD4ib"
      },
      "source": [
        "#Convert to lower case\n",
        "rgames2['new_cleaned_review'] = rgames2['new_cleaned_review'].str.lower()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK15h9Z4EAuD"
      },
      "source": [
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "#Function to get the word tokens\n",
        "def get_tokens(entry):\n",
        "    #Use nltk to get word tokens.\n",
        "    tokens = word_tokenize(entry)\n",
        "    \n",
        "    #Tokenize the word here. Returns the word if the word is a string. .isalpha() is a method that does this.\n",
        "    token_words = [w for w in tokens if w.isalpha()]\n",
        "    \n",
        "    return token_words\n",
        "\n",
        "#Function to remove the stopwords\n",
        "def remove_stop_words(entry):\n",
        "    \n",
        "    no_stopwords = [w for w in entry if not w in stopwords_list]\n",
        "    return (no_stopwords)\n",
        "\n",
        "\n",
        "#Function to delist the entries and join the words together in a string.\n",
        "def rejoin_words(entry):\n",
        "    \n",
        "    joined_words = ( \" \".join(entry))\n",
        "    return joined_words\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA_hXz_TEiYB",
        "outputId": "7a0dbca5-df7c-46b2-f6a9-480f7183a782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2ISH81-EF_o",
        "outputId": "83b569b6-5b1e-4a70-c4d9-ca44b6166f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "#Apply functions\n",
        "#Word tokenization first\n",
        "rgames2['words'] = rgames2['new_cleaned_review'].apply(get_tokens)\n",
        "\n",
        "#Remove stopwords next\n",
        "rgames2['words'] = rgames2['words'].apply(remove_stop_words)\n",
        "\n",
        "#Rejoin list to a sentence.\n",
        "rgames2['processed_review'] = rgames2['words'].apply(rejoin_words)\n",
        "\n",
        "#Iterate through the sentences.\n",
        "\n",
        "#Use the Counter function from the collections module to count words.\n",
        "#Use chain from itertools module to iterate.\n",
        "tally = Counter(chain.from_iterable(map(str.split, rgames2['processed_review'].tolist()))) \n",
        "\n",
        "#Create a series for the word counts.\n",
        "series = pd.Series(tally).sort_values(ascending=False)\n",
        "\n",
        "#Create a term frequency dataframe for the words and their frequency\n",
        "term_freq = series.reset_index()\n",
        "term_freq.columns = ['words','freq']\n",
        "\n",
        "\n",
        "#Top ten most mentioned words\n",
        "term_freq.head(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like</td>\n",
              "      <td>697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>games</td>\n",
              "      <td>631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>game</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one</td>\n",
              "      <td>406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sony</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>people</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>im</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>get</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dont</td>\n",
              "      <td>375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>would</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    words  freq\n",
              "0    like   697\n",
              "1   games   631\n",
              "2    game   582\n",
              "3     one   406\n",
              "4    sony   403\n",
              "5  people   400\n",
              "6      im   386\n",
              "7     get   378\n",
              "8    dont   375\n",
              "9   would   351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A-RkVRBEp5_"
      },
      "source": [
        "Nothing useful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBI4oilsEuH0"
      },
      "source": [
        "#Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaieMrHeExDR"
      },
      "source": [
        "###cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qPRAuulEteC"
      },
      "source": [
        "#Use function to create a new cleaned body column.\n",
        "rgames['cleaned body'] = rgames['body'].astype(str).apply(clean_comment)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVK4oArmFjVZ"
      },
      "source": [
        "attributes = ['games','buy','price', 'quality','graphics']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBC2CiUDFqlZ",
        "outputId": "654316f0-176b-44fc-a7f0-b6ae098c378e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "attributes_nlp = nlp('games, buy, price, quality, graphics')\n",
        "def get_similarity(review_words):\n",
        "    text_review = ' '.join(review_words)\n",
        "    review_nlp = nlp(text_review)\n",
        "    return review_nlp.similarity(attributes_nlp)\n",
        "\n",
        "rgames['similarity'] =  rgames['cleaned body'].apply(get_similarity)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EwRD_6KF4X2",
        "outputId": "be3cd801-d058-4079-ae9c-83044e053ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "similarity = rgames.groupby('author')['similarity'].mean().reset_index().sort_values(by='similarity',ascending = False)\n",
        "similarity['similarity'].mean()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5258203457489231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9vLJCXcGbSw"
      },
      "source": [
        "###Sentiment analysis using vader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufq-_sIcGef1",
        "outputId": "b3dd331d-1b03-4e22-c0a4-8ede9a07cfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pip install VADER"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting VADER\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/0d/df60a0ae9ffb63c409849d2909883963855d10e2ee9a5a71c97be41da300/vader-0.0.2-py3-none-any.whl (45kB)\n",
            "\r\u001b[K     |███████▏                        | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from VADER) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from VADER) (0.22.2.post1)\n",
            "Collecting sonopy\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/4d/862855fb391bc30351f90d6c50ea913df9d18b0ae3b6b8ef3c7aa3ac976f/sonopy-0.1.2.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from VADER) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->VADER) (0.16.0)\n",
            "Building wheels for collected packages: sonopy\n",
            "  Building wheel for sonopy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sonopy: filename=sonopy-0.1.2-cp36-none-any.whl size=2881 sha256=52c5742f703e47439b6d1903230473d83c5ddc89fe0918d8d554b46dbcd438d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/39/ba/b2f21d4fbcb362658c73f83c9502782300b0399aef3693b506\n",
            "Successfully built sonopy\n",
            "Installing collected packages: sonopy, VADER\n",
            "Successfully installed VADER-0.0.2 sonopy-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYNUPXxcGhkG",
        "outputId": "c013703b-0833-4b23-fc4d-3b013dd4f2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRpo9gLNGlH-"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTskCpfbGpDj"
      },
      "source": [
        "#Create dataframe with original reviews\n",
        "sent_games = rgames[['author','body']].copy()\n",
        "#Add in columns to store sentiment for the attributes\n",
        "sent_games['games_sentiment'] = 0\n",
        "sent_games['buy_sentiment'] = 0\n",
        "sent_games['price_sentiment'] = 0\n",
        "sent_games['quality_sentiment'] = 0\n",
        "sent_games['graphics_sentiment'] = 0\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJJjGT0lGvWH",
        "outputId": "2e0866db-75b8-4ce0-a838-9d14a4bb5d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nltk.download('vader_lexicon')\n",
        "vader = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw4HYtagGz9j"
      },
      "source": [
        "#Iterrate through the dataframe\n",
        "for i in sent_games.index:\n",
        "    #Get a review and split it into sentence tokens\n",
        "    review = sent_games.loc[i,'body']\n",
        "    review = sent_tokenize(review)\n",
        "    \n",
        "    #Store score values here\n",
        "    #Resets every time loop runs. This is intentional.\n",
        "    comp_games = []\n",
        "    comp_buy = []\n",
        "    comp_price = []\n",
        "    comp_quality = []\n",
        "    comp_graphics = []\n",
        "    \n",
        "    #Iterate through the sentence tokens. Get compound sentiment score if the word is present.\n",
        "    for sent_token in review:\n",
        "        if 'games' in sent_token.lower():\n",
        "            games_score = vader.polarity_scores(sent_token).get('compound')\n",
        "            comp_games.append(games_score)\n",
        "            \n",
        "        if 'buy' in sent_token.lower():\n",
        "            buy_score = vader.polarity_scores(sent_token).get('compound')\n",
        "            comp_buy.append(buy_score)\n",
        "            \n",
        "        if 'price' in sent_token.lower():\n",
        "            price_score = vader.polarity_scores(sent_token).get('compound')\n",
        "            comp_price.append(price_score)\n",
        "        if 'quality' in sent_token.lower():\n",
        "            quality_score = vader.polarity_scores(sent_token).get('compound')\n",
        "            comp_quality.append(quality_score)\n",
        "        if 'graphics' in sent_token.lower():\n",
        "            graphics_score = vader.polarity_scores(sent_token).get('compound')\n",
        "            comp_graphics.append(graphics_score)\n",
        "    \n",
        "    #Store each sentiment score in the array\n",
        "    if len(comp_games) == 0: #Nothing is in the list. No sentiment for the review.\n",
        "        sent_games.loc[i,'games_sentiment'] = None\n",
        "    else: #Balanced is in the review. Take the average of the list and store it.\n",
        "        #Taking average means to convert it into a numpy array and then using the np.mean\n",
        "        sent_games.loc[i,'games_sentiment'] = np.mean(np.array(comp_games))\n",
        "    \n",
        "    #Repeat conditions for attributes.\n",
        "    if len(comp_buy) == 0:\n",
        "        sent_games.loc[i,'buy_sentiment'] = None\n",
        "    else:\n",
        "        sent_games.loc[i,'buy_sentiment'] = np.mean(np.array(comp_buy))\n",
        "    if len(comp_price) == 0:\n",
        "        sent_games.loc[i,'price_sentiment'] = None\n",
        "    else:\n",
        "        sent_games.loc[i,'price_sentiment'] = np.mean(np.array(comp_price))\n",
        "    if len(comp_quality) == 0:\n",
        "        sent_games.loc[i,'quality_sentiment'] = None\n",
        "    else:\n",
        "        sent_games.loc[i,'quality_sentiment'] = np.mean(np.array(comp_quality))\n",
        "    if len(comp_graphics) == 0:\n",
        "        sent_games.loc[i,'graphics_sentiment'] = None\n",
        "    else:\n",
        "        sent_games.loc[i,'graphics_sentiment'] = np.mean(np.array(comp_graphics))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uE90aedHG6y"
      },
      "source": [
        "#Group all the sentiments of the review together\n",
        "avg_sent_games = sent_games.groupby(by=[\"author\"])[[\"games_sentiment\", \"buy_sentiment\", \"price_sentiment\",\"quality_sentiment\",\"graphics_sentiment\"]].mean()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwE2D_JZHMuE"
      },
      "source": [
        "#Sentiments that are not present are treated as Zero. \n",
        "#Want to pinpoint comments based on attributes.\n",
        "#Mean is simply adding five columns together and dividng by 5\n",
        "avg_sent_games['average_sentiment'] = (avg_sent_games['games_sentiment'].fillna(0)+avg_sent_games['buy_sentiment'].fillna(0)\n",
        " +avg_sent_games['price_sentiment'].fillna(0)+avg_sent_games['quality_sentiment'].fillna(0)+avg_sent_games['graphics_sentiment'].fillna(0))/5"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQcK6O9HHRwK",
        "outputId": "091ccc11-63bf-4c63-c288-c37ec9ece5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "avg_sent_games.sort_values(by='average_sentiment', ascending = False).fillna(0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games_sentiment</th>\n",
              "      <th>buy_sentiment</th>\n",
              "      <th>price_sentiment</th>\n",
              "      <th>quality_sentiment</th>\n",
              "      <th>graphics_sentiment</th>\n",
              "      <th>average_sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fyrael</th>\n",
              "      <td>0.929300</td>\n",
              "      <td>0.92930</td>\n",
              "      <td>0.92930</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.557580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diddaykong</th>\n",
              "      <td>0.531825</td>\n",
              "      <td>0.85775</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8402</td>\n",
              "      <td>0.445955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LocusAintBad</th>\n",
              "      <td>0.128900</td>\n",
              "      <td>0.39650</td>\n",
              "      <td>0.58225</td>\n",
              "      <td>0.9341</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.408350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DANK_BLUMPKIN</th>\n",
              "      <td>0.895700</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.8957</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.358280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a_to_the_g79</th>\n",
              "      <td>0.851900</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.340760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JackStillAlive</th>\n",
              "      <td>-0.520100</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.61870</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.227760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Voyager5555</th>\n",
              "      <td>-0.665400</td>\n",
              "      <td>-0.61240</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.255560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Xerosnake90</th>\n",
              "      <td>-0.670500</td>\n",
              "      <td>-0.67050</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.268200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandyChimp</th>\n",
              "      <td>-0.680800</td>\n",
              "      <td>-0.68080</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.272320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rioma117</th>\n",
              "      <td>-0.826800</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.58230</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.2732</td>\n",
              "      <td>-0.336460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2899 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                games_sentiment  ...  average_sentiment\n",
              "author                           ...                   \n",
              "Fyrael                 0.929300  ...           0.557580\n",
              "diddaykong             0.531825  ...           0.445955\n",
              "LocusAintBad           0.128900  ...           0.408350\n",
              "DANK_BLUMPKIN          0.895700  ...           0.358280\n",
              "a_to_the_g79           0.851900  ...           0.340760\n",
              "...                         ...  ...                ...\n",
              "JackStillAlive        -0.520100  ...          -0.227760\n",
              "Voyager5555           -0.665400  ...          -0.255560\n",
              "Xerosnake90           -0.670500  ...          -0.268200\n",
              "RandyChimp            -0.680800  ...          -0.272320\n",
              "Rioma117              -0.826800  ...          -0.336460\n",
              "\n",
              "[2899 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tSCZh7NHXDH",
        "outputId": "3803a21e-82ed-4356-b8f5-2e84d5dfec7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "avg_sent_games = avg_sent_games.apply('mean')\n",
        "avg_sent_games"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "games_sentiment       0.153131\n",
              "buy_sentiment         0.136190\n",
              "price_sentiment       0.114231\n",
              "quality_sentiment     0.202311\n",
              "graphics_sentiment    0.306042\n",
              "average_sentiment     0.009128\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}